---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a Ph.D. candidate in the Dept. of Psychology at Harvard University, advised by [Prof. George Alvarez](https://visionlab.harvard.edu/george/bio) and [Prof. Talia Konkle](https://konklab.fas.harvard.edu/#) in the [Vision Sciences Lab](https://visionlab.harvard.edu) and [Cognitive and Neural Organization Lab](https://konklab.fas.harvard.edu/#). I am grateful to be supported by the Graduate Fellowship at the [Kempner Institute for the Study of Natural and Artificial Vision](https://kempnerinstitute.harvard.edu/). I am broadly interested in how the human mind transforms visual sensory information into meaningful percepts of the world, and whether we can use artificial vision models to dissect the sophisticated mechanims that biological vision uses to isolate and segment different objects in a scene. 

<!-- I am grateful to be supported by the [Graduate Fellowship](https://kempnerinstitute.harvard.edu/news/kempner-institute-announces-recipients-of-inaugural-graduate-student-fellowships/) at the [Kempner Institute for the Study of Natural and Artificial Vision](https://kempnerinstitute.harvard.edu/). -->

Specifically, I am exploring the tuning and spatial topographies of proto-object representations and the mid-level mechanisms that lead to the emergence of an object's global shape information in both, humans and vision models. My recent work ventures into using self-supervised learning, knowledge distillation and vision-language alignment to identify the inductive biases that facilitate learning holistic shape representations that can capture human-like sensitivity to configural relations between object parts.

To achieve these goals, I use a multidisciplinary approach that combines computational models of vision, primarily deep neural networks, with behavioral psychophysics and neuroimaging data. By integrating these techniques, I aim to gain deeper insights into the emergent mechanistic signatures of mid-level computations that underlie biological and machine vision. Here's a [brief walkthrough](https://gsas.harvard.edu/news/seeing-how-we-see) about my ongoing research, and you can learn more about my background and previous work on the [Harvard Brain Science Initiative page](https://brain.harvard.edu/hbi_humans/fenil-rakesh-doshi/).

### Here is our recent work on holistic processing and shape perception in vision models
Link to [paper](https://arxiv.org/abs/2507.00493), [project page](https://www.fenildoshi.com/configural-shape/), and [tweet-thread](https://x.com/fenildoshi009/status/1940465973544603822?s=61)

<img src="https://feziodoshi.github.io/images/configural_shape_holistic_paper.png" alt="drawing" style="width:100%;height: auto;display: block;margin-left: auto;margin-right: auto; border: 3px solid black;"/>


### Check out our work on modeling cortical topographies
Link to [paper](https://www.science.org/doi/10.1126/sciadv.ade8187) and [tweet-thread](https://twitter.com/fenildoshi009/status/1567956934971768832?s=20&t=Dno1tBXnH3oVA13gnZeoRw)

<img src="https://feziodoshi.github.io/images/cover_cortical_topographies.png" alt="drawing" style="width:100%;height: auto;display: block;margin-left: auto;margin-right: auto; border: 3px solid black;"/>

### Here's some recent work on computational mechanims underlying mid-level object perception
Link to [preprint](https://www.biorxiv.org/content/10.1101/2024.06.11.598524v2)

<img src="https://feziodoshi.github.io/images/cover_contour_integration_dnns.png" alt="drawing" style="width:100%;height: auto;display: block;margin-left: auto;margin-right: auto; border: 3px solid black;"/>

### Talk on perceptual signatures of contour integration in humans and deep neural networks 
Presented at Vision Sciences Society 2022
{% include youtubePlayer.html id="PsmZAMGeV6A" %}

### Talk on a topographic model of the human visual system using self-organizing constraints
Presented at Vision Sciences Society 2021
{% include youtubePlayer.html id="zZvrIuoxU6Y" %}



